{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0326 1.nlp_Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'a man in the house' # untokenized string\n",
    "t = ['a', 'man', 'in', 'the', 'house'] # tokenized seqeuence of words as a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. nltk의 Text라는 함수\n",
    "\n",
    "string, list의 상태일때보다 nltk로 변환해야 다양한 기능 사용 할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = nltk.Text(t)\n",
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = nltk.Text(s.split())\n",
    "type(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "os.getcwd(os.getcwd()+r'/06_01.txt   ---->는 full path to 06_01.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = open(os.getcwd()+r'/06_01.txt', encoding = 'utf8').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "txt 파일을 열면 string type. [:nn] ~nn몇자까지 불러올 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(raw))\n",
    "print(len(raw))\n",
    "print(raw[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. word_tokenize 함수\n",
    "\n",
    "word_tokenize 함수를 사용하면 list type으로 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(raw)\n",
    "print(type(tokens))\n",
    "print(len(tokens))\n",
    "print(tokens[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Text 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nltk.Text는 string, list가 아닌 nltk.text.Text라는 type\n",
    "\n",
    "print하면 list 형태로 tekenize되어 나옴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. collocations: 연어 (연계되는 단어)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nltk.Text(tokens)\n",
    "print(type(text))\n",
    "print(text[:10])\n",
    "text.collocations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. concordance\n",
    "\n",
    "a.concordance('string', n, m)\n",
    "\n",
    "'string'이라는 단어를 기준으로 앞 뒤 n단어, 총 m줄을 찾는다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.concordance('great', 79, 25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. FreqDist 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "raw = nltk.corpus.gutenberg.raw('melville-moby_dick.txt')\n",
    "\n",
    "*nltk는 함수 뿐 아니라 data도 불러 올 수 있다. moby dick 의 raw, text string을 불러 온 것\n",
    "\n",
    "FreqDist = frequent distribution: 각 string별 얼마나 나왔는지\n",
    "\n",
    "[char for (char, count) in fdist.most_common(5)]\n",
    "\n",
    "*list안의 tuple- ( , ) for 문이 pair로 돈다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw = nltk.corpus.gutenberg.raw('melville-moby_dick.txt')\n",
    "fdist = nltk.FreqDist(raw)\n",
    "print(fdist.most_common(5))\n",
    "\n",
    "fdist = nltk.FreqDist(ch.lower() for ch in raw if ch.isalpha())\n",
    "print(fdist.most_common(5))\n",
    "[char for (char, count) in fdist.most_common(5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nltk의 data 중 사전같은거.. english 중 마지막 20~마지막까지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nltk.corpus.words.words('en')[-20:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nltk.corpus.words.words('en'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lord Ham; Fathers death; haue seene; Enter Polonius; thou hast; Enter\n",
      "King; Enter Hamlet; mine owne; set downe; thou art; wilt thou; Dost\n",
      "thou; haue heard; Father lost; Lord Polon; thou shalt; dead body;\n",
      "second Husband; Lord Hamlet; Scena Secunda\n"
     ]
    }
   ],
   "source": [
    "raw = nltk.corpus.gutenberg.raw('shakespeare-hamlet.txt')\n",
    "token = nltk.word_tokenize(raw)\n",
    "word = nltk.Text(token)\n",
    "word.collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 10 of 104 matches:\n",
      "same figure , like the King that 's dead Mar . Thou art a Scholler ; speake to it Horatio Barn . L\n",
      "e too Mar . Question it Horatio Hor . What art thou that vsurp'st this time of night , Together wi\n",
      " eyes Mar . Is it not like the King ? Hor . As thou art to thy selfe , Such was the very Armour he\n",
      "e it , though it blast me . Stay Illusion : If thou hast any sound , or vse of Voyce , Speake to m\n",
      "e do ease , and grace to me ; speak to me . If thou art priuy to thy Countries Fate ( Which happil\n",
      "ly foreknowing may auoyd ) Oh speake . Or , if thou hast vp-hoorded in thy life Extorted Treasure \n",
      "he Dane , And loose your voyce . What would'st thou beg Laertes , That shall not be my Offer , not\n",
      "rone of Denmarke to thy Father . What would'st thou haue Laertes ? Laer . Dread my Lord , Your lea\n",
      " lids Seeke for thy Noble Father in the dust ; Thou know'st 't is common , all that liues must dye\n",
      "u ; And these few Precepts in thy memory , See thou Character . Giue thy thoughts no tongue , Nor \n"
     ]
    }
   ],
   "source": [
    "word.concordance('thou', 99, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', 2892), ('.', 1879), ('the', 860), ('and', 605), ('of', 576), ('to', 574), (':', 566), ('I', 550), ('you', 479), ('?', 459)]\n",
      "[('e', 16338), ('t', 10853), ('o', 10441), ('a', 9027), ('h', 8208), ('i', 7940), ('n', 7611), ('s', 7568), ('r', 7147), ('l', 5452)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['e', 't', 'o', 'a', 'h', 'i', 'n', 's', 'r', 'l']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd = nltk.FreqDist(word)\n",
    "print(fd.most_common(10))\n",
    "\n",
    "rw = nltk.FreqDist(ch.lower() for ch in raw if ch.isalpha())\n",
    "print(rw.most_common(10))\n",
    "[char for (char, count) in rw.most_common(10)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
